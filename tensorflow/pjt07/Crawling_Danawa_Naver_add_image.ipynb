{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a392bd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8affe0",
   "metadata": {},
   "source": [
    "# 1. Danawa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03d6f6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 7-10 상품 정보 태그에서 원하는 정보를 추출하는 함수\n",
    "def danawa_get_prod_items(prod_items):\n",
    "    prod_data = []\n",
    "    for prod_item in prod_items:\n",
    "        if 'product-pot' in prod_item['class']:\n",
    "            continue  # 공백부분(‘li.prod_item.product-pot’) 제외하기\n",
    "        try:\n",
    "            # ① 상품명 가져오기\n",
    "            title = prod_item.select('p.prod_name > a')[0].text.strip()\n",
    "            # ② 스펙 목록 가져오기\n",
    "            spec_list = prod_item.select('div.spec_list')[0].text.strip()\n",
    "            # ③ 가격 정보 가져오기\n",
    "            price = prod_item.select('li.rank_one > p.price_sect > a > strong')[0].text.strip().replace(\",\", \"\")\n",
    "            # 상품평\n",
    "            rate = prod_item.select('div.point_num > strong')[0].text.strip()\n",
    "            # 참여수\n",
    "            opinion = prod_item.select('a.click_log_prod_content_count > strong')[0].text.strip()\n",
    "            \n",
    "            prod_data.append([title, spec_list, price, rate, opinion])\n",
    "        except:\n",
    "            pass  # 진행시 에러가 발생할 경우(광고 상품 등) 넘어가기\n",
    "    return prod_data\n",
    "\n",
    "def danawa_get_search_page_url(keyword, page):\n",
    "    return 'http://search.danawa.com/dsearch.php?query={}&volumeType=allvs&page={}&limit=30&sort=saveDESC&list=list&boost=true&addDelivery=N&tab=goods&tab=goods'.format(keyword, page)\n",
    "\n",
    "def danawa_start_crawling(keyword, total_page):\n",
    "    # setting\n",
    "    driver = webdriver.Chrome(service = Service('./chromedriver.exe'))\n",
    "    driver.implicitly_wait(3)\n",
    "\n",
    "    prod_data_total = []\n",
    "\n",
    "    for page in tqdm(range(1, total_page+1)):\n",
    "\n",
    "        # open chrome browser\n",
    "        url = danawa_get_search_page_url(keyword, page)\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "\n",
    "        # get html source of the page\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        # get info\n",
    "        prod_items = soup.select('div.main_prodlist > ul.product_list > li.prod_item')\n",
    "        prod_item_list = danawa_get_prod_items(prod_items)\n",
    "\n",
    "        prod_data_total = prod_data_total + prod_item_list\n",
    "        \n",
    "        return prod_data_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "33ca4230",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7d73b083314a11b185147fbbfe95c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prod_data_total = danawa_start_crawling('트리트먼트', 10)\n",
    "\n",
    "data = pd.DataFrame(prod_data_total)\n",
    "data.columns = ['title', 'spec_list', 'price', 'rate', 'opinion']\n",
    "data.to_excel('./treatment_danawa_10page.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769cde58",
   "metadata": {},
   "source": [
    "# Coupang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23bb1af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coupang_get_search_page_url(keyword, page):\n",
    "    return 'https://www.coupang.com/np/search?q={}&channel=user&component=&eventCategory=SRP&trcid=&traid=&sorter=scoreDesc&minPrice=&maxPrice=&priceRange=&filterType=&listSize=36&filter=&isPriceRange=false&brand=&offerCondition=&rating=0&page={}&rocketAll=false&searchIndexingToken=1=6&backgroundColor='.format(keyword, page)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a33c9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d0730378b946c9a660d994e16d7ee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# setting\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.88 Safari/537.36\")\n",
    "\n",
    "driver = webdriver.Chrome(service = Service('./chromedriver.exe'))\n",
    "driver.implicitly_wait(3)\n",
    "\n",
    "keyword = '샴푸'\n",
    "total_page = 1\n",
    "\n",
    "prod_data_total = []\n",
    "\n",
    "for page in tqdm(range(1, total_page+1)):\n",
    "\n",
    "    # open chrome browser\n",
    "    url = coupang_get_search_page_url(keyword, page)\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "\n",
    "    # get html source of the page\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # get info\n",
    "    prod_items = soup.select('ul#productList.search-product-list')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd5fc8d",
   "metadata": {},
   "source": [
    "# 2. Naver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "159ff655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 7-10 상품 정보 태그에서 원하는 정보를 추출하는 함수\n",
    "def naver_get_prod_items(prod_items):\n",
    "    prod_data = []\n",
    "    for prod_item in prod_items:\n",
    "        if 'product-pot' in prod_item['class']:\n",
    "            continue  # 공백부분(‘li.prod_item.product-pot’) 제외하기\n",
    "            print(1)\n",
    "        try:\n",
    "            # ① 상품명 가져오기\n",
    "            title = prod_item.select('a.basicList_link__1MaTN')[0].text.strip()\n",
    "            # ② 스펙 목록 가져오기\n",
    "            spec_list = [x.text.strip() for x in prod_item.select('a.basicList_detail__27Krk')]\n",
    "            # ③ 가격 정보 가져오기\n",
    "            price = prod_item.select('span.price_num__2WUXn')[0].text.strip()\n",
    "            # 상품평\n",
    "            rate = prod_item.select('span.basicList_star__3NkBn')[0].text.split(' ')[-1]\n",
    "            # 참여수\n",
    "            opinion = prod_item.select('em.basicList_num__1yXM9')[0].text\n",
    "            # site\n",
    "            url = prod_item.select('a.thumbnail_thumb__3Agq6')[0]['href']\n",
    "            \n",
    "            prod_data.append([title, spec_list, price, rate, opinion, url])\n",
    "        except:\n",
    "            pass  # 진행시 에러가 발생할 경우(광고 상품 등) 넘어가기\n",
    "    return prod_data\n",
    "\n",
    "def naver_get_search_page_url(keyword, page):\n",
    "    return 'https://search.shopping.naver.com/search/all?frm=NVSHATC&origQuery={}&pagingIndex={}&pagingSize=40&productSet=total&query={}&sort=rel&timestamp=&viewType=list'.format(keyword, page, keyword)\n",
    "\n",
    "def naver_start_crawling(keyword, total_page):\n",
    "    # setting\n",
    "    driver = webdriver.Chrome(service = Service('./chromedriver.exe'))\n",
    "    driver.implicitly_wait(3)\n",
    "\n",
    "    prod_data_total = []\n",
    "\n",
    "    for page in tqdm(range(1, total_page+1)):\n",
    "\n",
    "        # open chrome browser\n",
    "        url = naver_get_search_page_url(keyword, page)\n",
    "        driver.get(url)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # 최하단으로 스크롤링 하여 모든 데이터 표출\n",
    "        driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "        time.sleep(3)\n",
    "        \n",
    "        # get html source of the page\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        # get info\n",
    "        prod_items = soup.select('li.basicList_item__2XT81')\n",
    "        prod_item_list = naver_get_prod_items(prod_items)\n",
    "\n",
    "        prod_data_total = prod_data_total + prod_item_list\n",
    "        \n",
    "    return prod_data_total\n",
    "\n",
    "\n",
    "import datetime\n",
    "def doScrollDown(whileSeconds):\n",
    "    global driver\n",
    "    start = datetime.datetime.now()\n",
    "    end = start + datetime.timedelta(seconds=whileSeconds)\n",
    "    i = 0\n",
    "    while True:\n",
    "        driver.execute_script(f'window.scrollTo(0, {3000 + (i)*500});')\n",
    "        i+=1\n",
    "        time.sleep(0.5)\n",
    "        if datetime.datetime.now() > end:\n",
    "            break\n",
    "            \n",
    "            \n",
    "def naver_image_crawling(urls):\n",
    "    urls = data.url\n",
    "    driver = webdriver.Chrome(service = Service('./chromedriver.exe'))\n",
    "    driver.implicitly_wait(3)\n",
    "\n",
    "\n",
    "    prod_data_total = []\n",
    "\n",
    "    for url in tqdm(urls):\n",
    "\n",
    "        # open chrome browser\n",
    "        driver.get(url)\n",
    "\n",
    "        # 하단으로 x만큼만 스크롤을 해야 이미지 표출\n",
    "        doScrollDown(3)\n",
    "\n",
    "        # get html source of the page\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        try:\n",
    "            product_image = soup.select('div.image_thumb__20xyr > img')[0]['src']\n",
    "        except:\n",
    "            product_image = np.nan\n",
    "        try:\n",
    "            ocr_image = soup.select('p > img')[0]['src']\n",
    "        except:\n",
    "            ocr_image = np.nan\n",
    "\n",
    "        # get image data\n",
    "        prod_data_total = prod_data_total + [product_image, ocr_image]\n",
    "        \n",
    "        return prod_data_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "35f38ee8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c6286500d24c16b0327c4b30e48fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prod_data_total = naver_start_crawling('샴푸', 10)\n",
    "\n",
    "data = pd.DataFrame(prod_data_total)\n",
    "data.columns = ['title', 'spec_list', 'price', 'rate', 'opinion', 'url']\n",
    "data.to_excel('./shampoo_naver_10page_new.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "814568ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "def doScrollDown(whileSeconds):\n",
    "    global driver\n",
    "    start = datetime.datetime.now()\n",
    "    end = start + datetime.timedelta(seconds=whileSeconds)\n",
    "    i = 0\n",
    "    while True:\n",
    "        driver.execute_script(f'window.scrollTo(0, {1500 + (i)*500});')\n",
    "        i+=1\n",
    "        time.sleep(0.1)\n",
    "        if datetime.datetime.now() > end:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "19b9beb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "456dbf333d434d19bac05c70617ef874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# naver_image_crawling\n",
    "data = pd.read_excel('./shampoo_naver_10page_new.xlsx')\n",
    "urls = data.url\n",
    "prod_data_total = []\n",
    "\n",
    "driver = webdriver.Chrome(service = Service('./chromedriver.exe'))\n",
    "driver.implicitly_wait(3)\n",
    "\n",
    "for url in tqdm(urls):\n",
    "\n",
    "    # open chrome browser\n",
    "    driver.get(url)\n",
    "\n",
    "    # 하단으로 x만큼만 스크롤을 해야 이미지 표출\n",
    "    doScrollDown(2)\n",
    "    \n",
    "    # get html source of the page\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    try:\n",
    "        product_image = soup.select('div.image_thumb__20xyr > img')[0]['src']\n",
    "    except:\n",
    "        product_image = np.nan\n",
    "    try:\n",
    "        ocr_image = []\n",
    "        for img in soup.select('div.imageSpecInfo_product_img__2buWL')[0].select('img'):\n",
    "            src = img['src']\n",
    "            if 'data' in src:\n",
    "                continue\n",
    "            else:\n",
    "                ocr_image.append(src)\n",
    "    except:\n",
    "        ocr_image = np.nan\n",
    "    \n",
    "    # get image data\n",
    "    prod_data_total = prod_data_total + [[product_image, ocr_image]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "025b7bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GW\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "data[['image','ocr_image']] = prod_data_total\n",
    "\n",
    "func = lambda x : x.replace(['[]'], np.nan, inplace=True)\n",
    "data.apply(func)\n",
    "\n",
    "data.to_excel('./shampoo_naver_10page_with_image.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf88200",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
